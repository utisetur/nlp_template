backbone:
  class_name: transformers.get_linear_schedule_with_warmup
  step: step
  monitor: ${training.metric}

classifier:
  class_name: torch.optim.lr_scheduler.ReduceLROnPlateau
  step: epoch
  monitor: valid_loss  # train_${training.metric}
  params:
    mode: 'min' # ${training.mode}
    factor: 0.1  # 0.1
    patience: 2

params:
  num_warmup_steps: 100  # The number of steps for the warmup phase.
  #  lr_lambda: 'lambda epoch: 1. / (1. + 0.05 * epoch)'
  num_training_steps: 1635  # The total number of training steps.