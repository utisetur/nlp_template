{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n",
      "True\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.core.display import display\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, RobertaModel, DataCollatorWithPadding\n",
    "from pipeline.datasets.rte_dataset import RTEDataset, RTETestDataset\n",
    "from pipeline.models.roberta_classifier import RoBERTaClassifier\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               premise  \\\nidx                                                      \n0    No Weapons of Mass Destruction Found in Iraq Yet.   \n1    A place of sorrow, after Pope John Paul II die...   \n2    Herceptin was already approved to treat the si...   \n3    Judie Vivian, chief executive at ProMedica, a ...   \n4    A man is due in court later charged with the m...   \n\n                                            hypothesis           label  \nidx                                                                     \n0           Weapons of Mass Destruction Found in Iraq.  not_entailment  \n1    Pope Benedict XVI is the new leader of the Rom...      entailment  \n2        Herceptin can be used to treat breast cancer.      entailment  \n3    The previous name of Ho Chi Minh City was Saigon.      entailment  \n4    Paul Stewart Hutchinson is accused of having s...  not_entailment  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>idx</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n      <td>Weapons of Mass Destruction Found in Iraq.</td>\n      <td>not_entailment</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A place of sorrow, after Pope John Paul II die...</td>\n      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Herceptin was already approved to treat the si...</td>\n      <td>Herceptin can be used to treat breast cancer.</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n      <td>entailment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A man is due in court later charged with the m...</td>\n      <td>Paul Stewart Hutchinson is accused of having s...</td>\n      <td>not_entailment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2490, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_json(path_or_buf='../data/RTE/train.jsonl', lines=True).set_index('idx')\n",
    "val_data = pd.read_json(path_or_buf='../data/RTE/val.jsonl', lines=True).set_index('idx')\n",
    "test_data = pd.read_json(path_or_buf='../data/RTE/test.jsonl', lines=True)#.set_index('idx')\n",
    "\n",
    "display(train_data.head())\n",
    "print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "entailment        1249\nnot_entailment    1241\nName: label, dtype: int64"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9967974379503602, 1.0032232070910556]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "\n",
    "labels_map = {\n",
    "            'not_entailment': 0,\n",
    "            'entailment': 1,\n",
    "        }\n",
    "\n",
    "train_y = np.array(train_data['label'].values)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=['entailment', 'not_entailment'],\n",
    "            y=train_y\n",
    "        )\n",
    "class_weights = list(class_weights)\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "['entailment', 'not_entailment']"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(train_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0,  3084, 28054,     9,  5370, 43207, 11911,    11,  3345,  3507,\n             4,     2,     2, 48637,     9,  5370, 43207, 11911,    11,  3345,\n             4,     2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\n",
    "    'No Weapons of Mass Destruction Found in Iraq Yet.',\n",
    "    'Weapons of Mass Destruction Found in Iraq.',\n",
    "    padding=False,\n",
    "    truncation=True,\n",
    "    max_length=150,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=True,\n",
    "    return_tensors='pt',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n    (position_embeddings): Embedding(514, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.9460, grad_fn=<NllLossBackward0>)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input_tensor = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input_tensor, target)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.5382,  0.6787,  0.8633, -0.4784, -0.4631],\n        [-0.0049,  0.1128, -0.6147, -1.2283,  0.5026],\n        [ 0.7810,  0.9470,  3.2067, -0.9198,  0.1095]], requires_grad=True)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0, 1])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 5]), torch.Size([3]))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, target.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.8654, grad_fn=<DivBackward1>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input_tensor = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input_tensor, target)\n",
    "output\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0187, 0.3116, 0.3325, 0.0450, 0.2923],\n        [0.1780, 0.5081, 0.0480, 0.1720, 0.0940],\n        [0.0477, 0.4098, 0.0778, 0.0860, 0.3788]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss = nn.BCEWithLogitsLoss(weight=torch.tensor([1.0, 2.0]))\n",
    "# inputs = torch.randn(3, requires_grad=True)\n",
    "# target = torch.empty(3).random_(2)\n",
    "# output = loss(inputs, target)\n",
    "# output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# for row in train_data.values:\n",
    "#     tokenizer.encode(row[0], row[1]\n",
    "#     print(i)\n",
    "#     1/0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([    0,   250,   317,     9, 26130,     6,    71,  8509,   610,  1206,\n          3082,   962,     6,  1059,    10,   317,     9,  4821,     6,    25,\n          7733,  4019, 15828,  4366,    11,  3301,  1568,     7,  2458,     5,\n          8809,     9,    92,  8509, 20742, 42171,     4,     2,     2, 36017,\n         20742, 42171,    16,     5,    92,   884,     9,     5,  7733,  4019,\n          2197,     4,     2]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1]),\n 'label': 1}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = RTEDataset(\n",
    "    data=train_data.values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=200,\n",
    ")\n",
    "\n",
    "dataset.__getitem__(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([53])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(1)['input_ids'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'<s>Yet, we now are discovering that antibiotics are losing their effectiveness against illness. Disease-causing bacteria are mutating faster than we can come up with new antibiotics to fight the new variations.</s></s>Bacteria is winning the war against antibiotics.</s>'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.__getitem__(1)['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "lens = []\n",
    "for i in range(len(dataset)):\n",
    "    lens.append(len(dataset.__getitem__(i)['input_ids']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "196.0"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(lens, 99)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "292"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(lens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "collator = DataCollatorWithPadding(\n",
    "            tokenizer=tokenizer,\n",
    "            padding='longest',\n",
    "        )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=8,\n",
    "            # num_workers=cfg.datamodule.num_workers,\n",
    "            # pin_memory=cfg.datamodule.pin_memory,\n",
    "            collate_fn=collator,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "batch = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'attention_mask', 'labels'])"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reduction': 'sum', 'weight': [1.0, 2.0]}\n"
     ]
    }
   ],
   "source": [
    "loss_cfg = OmegaConf.load('../cfg/loss/bce_logits.yaml')\n",
    "loss_cfg.params.weight = [1.0, 2.0]\n",
    "print(loss_cfg.params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "float"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss_cfg.params.weight[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_cfg = OmegaConf.load('../cfg/model/roberta.yaml')\n",
    "model_cfg['model'] = model_cfg\n",
    "\n",
    "clf = RoBERTaClassifier(model_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4469, 0.5531],\n        [0.4527, 0.5473],\n        [0.4516, 0.5484],\n        [0.4506, 0.5494],\n        [0.4499, 0.5501],\n        [0.4493, 0.5507],\n        [0.4465, 0.5535],\n        [0.4492, 0.5508]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp = dataset.__getitem__(1)\n",
    "logits, probs = clf(**batch)\n",
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.1301,  0.0831],\n         [-0.1360,  0.0536],\n         [-0.1255,  0.0689],\n         [-0.1271,  0.0711],\n         [-0.1330,  0.0680],\n         [-0.1313,  0.0721],\n         [-0.1313,  0.0835],\n         [-0.1341,  0.0700]], grad_fn=<AddmmBackward0>),\n torch.Size([8, 2]))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 0, 1, 0, 0, 0, 1, 1]), torch.Size([8]))"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'], batch['labels'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4469, 0.5531],\n        [0.4527, 0.5473],\n        [0.4516, 0.5484],\n        [0.4506, 0.5494],\n        [0.4499, 0.5501],\n        [0.4493, 0.5507],\n        [0.4465, 0.5535],\n        [0.4492, 0.5508]], grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=1)\n",
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [0.]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'].float().unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.7228, grad_fn=<NllLossBackward0>)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(logits, batch['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3750)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "acc = torchmetrics.Accuracy()\n",
    "acc(logits, batch['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "model_names = glob.glob(f'../outputs/2022-03-21_09-38-12/saved_models/*')\n",
    "best_model = [name for name in model_names if 'best' in name][0]\n",
    "checkpoint = torch.load(best_model)\n",
    "clf.load_state_dict(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'../outputs/2022-03-21_09-38-12/saved_models/best_epoch=5-val_accuracy=0.7545.pth'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "NotSupportedError",
     "evalue": "Compiled functions can't take variable number of arguments or use keyword-only arguments with defaults:\n  File \"/home/nbaranov/projects/personal/nlp_template/pipeline/models/roberta_classifier.py\", line 24\n        input_ids,\n        attention_mask=None,\n        *args, **kwargs\n                ~~~~~~~ <--- HERE\n    ):\n        model_output = self.model(\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotSupportedError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-50-dc5099617add>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscript\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Save to file\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'../outputs/2022-03-21_09-38-12/saved_models/best_model_jit.pt'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# This line is equivalent to the previous\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_script.py\u001B[0m in \u001B[0;36mscript\u001B[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001B[0m\n\u001B[1;32m   1255\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModule\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1256\u001B[0m         \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_prepare_scriptable_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1257\u001B[0;31m         return torch.jit._recursive.create_script_module(\n\u001B[0m\u001B[1;32m   1258\u001B[0m             \u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recursive\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfer_methods_to_compile\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         )\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module\u001B[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001B[0m\n\u001B[1;32m    449\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_tracing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m         \u001B[0mAttributeTypeIsSupportedChecker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcheck\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 451\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mcreate_script_module_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconcrete_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mcreate_script_module_impl\u001B[0;34m(nn_module, concrete_type, stubs_fn)\u001B[0m\n\u001B[1;32m    461\u001B[0m     \"\"\"\n\u001B[1;32m    462\u001B[0m     \u001B[0mcpp_module\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_module_with_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconcrete_type\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjit_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 463\u001B[0;31m     \u001B[0mmethod_stubs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstubs_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    464\u001B[0m     \u001B[0mproperty_stubs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_property_stubs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    465\u001B[0m     \u001B[0mhook_stubs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpre_hook_stubs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_hook_stubs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36minfer_methods_to_compile\u001B[0;34m(nn_module)\u001B[0m\n\u001B[1;32m    730\u001B[0m     \u001B[0mstubs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    731\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mmethod\u001B[0m \u001B[0;32min\u001B[0m \u001B[0muniqued_methods\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 732\u001B[0;31m         \u001B[0mstubs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmake_stub_from_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnn_module\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    733\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0moverload_stubs\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstubs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    734\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mmake_stub_from_method\u001B[0;34m(nn_module, method_name)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;31m# In this case, the actual function object will have the name `_forward`,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;31m# even though we requested a stub for `forward`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mmake_stub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/_recursive.py\u001B[0m in \u001B[0;36mmake_stub\u001B[0;34m(func, name)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmake_stub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[0mrcb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_jit_internal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateResolutionCallbackFromClosure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m     \u001B[0mast\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_jit_def\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"RecursiveScriptModule\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mScriptMethodStub\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrcb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mast\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/frontend.py\u001B[0m in \u001B[0;36mget_jit_def\u001B[0;34m(fn, def_name, self_name, is_classmethod)\u001B[0m\n\u001B[1;32m    262\u001B[0m         \u001B[0mpdt_arg_types\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtype_trace_db\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_args_types\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mqualname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 264\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbuild_def\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparsed_def\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn_def\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtype_line\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdef_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpdt_arg_types\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpdt_arg_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    265\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[0;31m# TODO: more robust handling of recognizing ignore context manager\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/frontend.py\u001B[0m in \u001B[0;36mbuild_def\u001B[0;34m(ctx, py_def, type_line, def_name, self_name, pdt_arg_types)\u001B[0m\n\u001B[1;32m    300\u001B[0m                        py_def.col_offset + len(\"def\"))\n\u001B[1;32m    301\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 302\u001B[0;31m     \u001B[0mparam_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuild_param_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpy_def\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpdt_arg_types\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    303\u001B[0m     \u001B[0mreturn_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpy_def\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'returns'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/03_nlp/edu_nlp/lib/python3.8/site-packages/torch/jit/frontend.py\u001B[0m in \u001B[0;36mbuild_param_list\u001B[0;34m(ctx, py_args, self_name, pdt_arg_types)\u001B[0m\n\u001B[1;32m    324\u001B[0m         \u001B[0mexpr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpy_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwarg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m         \u001B[0mctx_range\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_range\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlineno\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexpr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcol_offset\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexpr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcol_offset\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mNotSupportedError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mctx_range\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_vararg_kwarg_err\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    327\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mpy_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvararg\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m         \u001B[0mexpr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpy_args\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvararg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotSupportedError\u001B[0m: Compiled functions can't take variable number of arguments or use keyword-only arguments with defaults:\n  File \"/home/nbaranov/projects/personal/nlp_template/pipeline/models/roberta_classifier.py\", line 24\n        input_ids,\n        attention_mask=None,\n        *args, **kwargs\n                ~~~~~~~ <--- HERE\n    ):\n        model_output = self.model(\n"
     ]
    }
   ],
   "source": [
    "def convert_to_jit(model: nn.Module, save_name: str, cfg) -> None:\n",
    "    input_shape = (1, 3, cfg.datamodule.main_image_size, cfg.datamodule.main_image_size)\n",
    "    target_shape = 1\n",
    "    # out_path = f'saved_models/{save_name}_jit.pt'\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = torch.ones(input_shape).float().to(device)\n",
    "    target_tensor = torch.ones(target_shape, dtype=torch.long).to(device)\n",
    "    traced_model = torch.jit.trace(model, (input_tensor, target_tensor))\n",
    "    torch.jit.save(traced_model, save_name)\n",
    "\n",
    "\n",
    "convert_to_jit(clf, '../outputs/2022-03-21_09-38-12/saved_models/best_model_jit.pt', model_cfg)\n",
    "\n",
    "# m = torch.jit.script(clf)\n",
    "#\n",
    "# # Save to file\n",
    "# torch.jit.save(m, '../outputs/2022-03-21_09-38-12/saved_models/best_model_jit.pt')\n",
    "# This line is equivalent to the previous\n",
    "# m.save(\"scriptmodule.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([\"Mangla was summoned after Madhumita's sister Nidhi Shukla, who was the first witness in the case.\",\n       'Shukla is related to Mangla.', 0], dtype=object)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.values[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "{'idx': 0,\n 'input_ids': tensor([    0,   448,  1097,  2560,    21, 17323,    71,  4145, 18257,  3119,\n            18,  2761, 40371,  3592,   840,  1350,  2560,     6,    54,    21,\n             5,    78,  4562,    11,     5,   403,     4,     2,     2,  3609,\n          1350,  2560,    16,  1330,     7, 12756,  2560,     4,     2]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = RTETestDataset(data=test_data.values[:10], tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "test_dataset.__getitem__(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=64,\n",
    "            # num_workers=self.cfg.datamodule.num_workers,\n",
    "            # pin_memory=self.cfg.datamodule.pin_memory,\n",
    "            collate_fn=collator,\n",
    "            shuffle=False,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def get_test_scores(model, test_dataloader):\n",
    "    # torch.set_grad_enabled(False)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_dataloader:\n",
    "            logits = model(**batch)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            y_prob, y_pred = torch.max(probs, dim=1)\n",
    "            all_preds.extend(y_pred.numpy())\n",
    "            all_probs.extend(probs.detach().cpu().numpy())\n",
    "    return all_preds, all_probs\n",
    "\n",
    "\n",
    "all_preds, all_probs = get_test_scores(clf, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'idx': 0, 'label': 'entailment'},\n {'idx': 1, 'label': 'entailment'},\n {'idx': 2, 'label': 'entailment'},\n {'idx': 3, 'label': 'entailment'},\n {'idx': 4, 'label': 'entailment'},\n {'idx': 5, 'label': 'not_entailment'},\n {'idx': 6, 'label': 'entailment'},\n {'idx': 7, 'label': 'not_entailment'},\n {'idx': 8, 'label': 'not_entailment'},\n {'idx': 9, 'label': 'entailment'}]"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_submission(test_dataset, test_preds):\n",
    "    \"\"\"\n",
    "    {\"idx\": 12, \"label\": \"not_entailment\"}\n",
    "    {\"idx\": 13, \"label\": \"entailment\"}\n",
    "    \"\"\"\n",
    "    tag2label = {v: k for k,v in test_dataset.labels_map.items()}\n",
    "    submission = []\n",
    "    for idx in [i[-1] for i in test_dataset.data]:\n",
    "        submission.append({'idx': idx, 'label': tag2label[test_preds[idx]]})\n",
    "\n",
    "    return submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset super_glue (../data/super_glue/rte/1.0.2/2fb163bca9085c1deb906aff20f00c242227ff704a4e8c9cfdfe820be3abfc83)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('super_glue', 'rte', cache_dir='../data/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['premise', 'hypothesis', 'idx', 'label'],\n    num_rows: 3000\n})"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hypothesis': 'Shukla is related to Mangla.', 'idx': 0, 'label': -1, 'premise': \"Mangla was summoned after Madhumita's sister Nidhi Shukla, who was the first witness in the case.\"}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(dataset['test'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.device"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "type(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}